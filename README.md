# Cloud Embeddings: evaluate, finetune, deploy and store state-of-the-art pretrained embeddings

A repository for tackling cloud text pre-trained embeddings, from evaluation to deployment, including fine-tuning and vector stores, with an AWS cloud lens, with pretrained HuggingFace ðŸ¤— embeddings and AWS.

A series of blog posts is coming soon to give more contexts to this part ðŸš§.

## Why do embeddings matter?

They're at the backbone of multiple ML systems we encounter every day; plus, as LLM encounter increasing popularity, the use-case of retrieval augmented generation (RAG) is a professional use of GenAI that heavily relies on embeddings.


## Repository structure

### Evaluate
Evaluate SOTA embeddings with [MTEB](https://huggingface.co/blog/mteb) and SageMaker Processing.

### Finetune

Modern, LoRA finetuning embeddings with ðŸ¤— HuggingFace and SageMaker Training.

### Deploy

Automated pretrained embedding deployment with AWS CDK.

### Store
__TO DO__
 

