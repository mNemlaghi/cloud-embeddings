{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e37aa741-06f0-4d92-a154-97c53fe67bfc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluate Embedding with MTEB package and SageMaker processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3f80f8-58e0-4eb8-a07a-beca2058cbde",
   "metadata": {
    "tags": []
   },
   "source": [
    "The objective of this notebook is to evaluate embeddings with MTEB on a Sentence Similarity task. Cloud-wise, we'll use SageMaker processing for spinning up and down computing resources without the hassle of managing them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac095646-8efd-49ab-b50d-26865f4f2975",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup and general S3 bucket configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c42d9a4-6c3b-48a9-b96b-60de80c1eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c5590e-a7da-41a4-ab00-667dc40a0234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import session\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session=session.Session()\n",
    "\n",
    "BUCKET=sagemaker_session.default_bucket()\n",
    "S3_OUTPUT_PATH=\"mteb/eval\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04ecab6-b495-4b21-8d73-01fe6558f947",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using a SageMaker processing script for Sentence Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065facbd-7994-4b83-8633-002894f93f32",
   "metadata": {},
   "source": [
    "Let's create a repository for handling sentence transformers evaluation, dedicated to STS Benchmark. First we need to create a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4667a02b-24f7-455e-817e-bb0c23431dce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p sbertscripts/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc184cf-14b2-4c1f-bce6-dca2b94ef3dc",
   "metadata": {},
   "source": [
    "Now we just need to create an evaluation script. We'll focus on [STS Benchmark task](https://paperswithcode.com/dataset/sts-benchmark) and English only language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8122e31-486d-48bd-a03f-c5f7783849cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile sbertscripts/embeval.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from mteb import MTEB\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from mteb.tasks import STSBenchmarkSTS\n",
    "\n",
    "def stsb_mteb_evaluate_model(model, output_folder)->None:\n",
    "    evaluation = MTEB(tasks=[STSBenchmarkSTS(langs=[\"en\"])], task_langs=['en'])\n",
    "    results = evaluation.run(model, output_folder=output_folder, eval_splits=['test'])\n",
    "    return results\n",
    "\n",
    "if __name__=='__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model-name\")\n",
    "    os.path.join(\"/opt/ml/processing/evaluation\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "    print(\"Received arguments {}\".format(args))\n",
    "    output_path_folder = \"/opt/ml/processing/eval/\"\n",
    "    model = SentenceTransformer(args.model_name, output_path_folder)\n",
    "    res = stsb_mteb_evaluate_model(model, output_path_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330452bf-a182-4cf6-8a25-a1a2d0c45d7f",
   "metadata": {},
   "source": [
    "Although we're going to use a pre-built container, we will customize it in order to leverage use of MTEB package. In order to to so, we need to add a `requirements.txt`file in the scripts directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e59f4a0-c2ad-458e-b0a1-f6b710587fd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile sbertscripts/requirements.txt\n",
    "transformers\n",
    "mteb\n",
    "datasets\n",
    "accelerate==0.20.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8ba43f-91c9-40ae-bfd7-b2c0a86e8c01",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Rationale for the use of PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92608e2-02e1-420c-9fca-c44b5e73cab3",
   "metadata": {},
   "source": [
    "At the time of writing, HuggingFace SageMaker processing doesn't have GPU image. Since, instead of using GPU-based instances, this time we'll think in cost-effective manner and use CPUS: since it needs to be further analyzed, an evaluation output is not immediatelty needed in a low latency manner.\n",
    "\n",
    "Hence, we'll use PyTorch processor, with CPU support. For each sentence transformer model chosen, we're going to launch a processing job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8404f0-9814-4713-8f81-8a650a7a7152",
   "metadata": {},
   "source": [
    "### Launching SageMaker processing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075c6ac4-1ccd-4124-9b27-2d983f28c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "def run_sm_processing_job(model_name, script_dir = \"sbertscripts\"):\n",
    "    #Initialize the PyTorch Processor\n",
    "    model_suffix = model_name.split('/')[-1]\n",
    "    hfp = PyTorchProcessor(\n",
    "        role=get_execution_role(), \n",
    "        instance_count=1,\n",
    "        instance_type='ml.m5.2xlarge',\n",
    "        framework_version='1.13.1',\n",
    "        base_job_name=f\"mteb-eval-{model_suffix}\",\n",
    "        py_version=\"py39\",\n",
    "        max_runtime_in_seconds=600\n",
    "    )\n",
    "\n",
    "    #Run the processing job\n",
    "    s3_destination=f's3://{BUCKET}/{S3_OUTPUT_PATH}/{model_name}'\n",
    "    runnah=hfp.run(\n",
    "        code='embeval.py',\n",
    "        source_dir=script_dir,\n",
    "        outputs=[\n",
    "            ProcessingOutput(output_name='eval', source='/opt/ml/processing/eval/', destination=s3_destination)\n",
    "        ],\n",
    "        arguments = [\"--model-name\", model_name], \n",
    "        wait=False\n",
    "    )\n",
    "    return {\"s3eval\":s3_destination, \"model_name\":model_name, \"processor\":hfp}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75be7b60-0446-4b7b-9153-7c98af0dce58",
   "metadata": {},
   "source": [
    "Let's submit these for processing job for every SBERT model we want to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd15fc48-b9a0-4478-9d98-d80a45728c61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "l=[]\n",
    "sberts = [\"sentence-transformers/all-mpnet-base-v2\", \"sentence-transformers/all-MiniLM-L6-v2\", \"intfloat/e5-large-v2\"]\n",
    "for model_name in sberts:\n",
    "    l.append(run_sm_processing_job(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e238025c-05e6-4624-b7f4-9ce6d19a45fe",
   "metadata": {},
   "source": [
    "Note that we put `wait=False` parameter so we might need to wait until processing jobs are all complete.\n",
    "\n",
    "__TO DO__: add time handler until job completion based on job completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c99a34-1b7b-4032-bc6a-a9bc941794af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## TO DO: add time handler until job completion based on job completion.\n",
    "m=l[0]['processor']\n",
    "mm=m.latest_job.describe()['ProcessingJobStatus']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c28e3a-d339-4bad-b4b2-a5253a6b06e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's collect the results from their respective buckets inside a local `sbertresults` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e00beac-42ae-4c56-ba5f-180c3fc8db90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf sbertresults/\n",
    "!aws s3 cp --recursive s3://{BUCKET}/{S3_OUTPUT_PATH}/sentence-transformers/ ./sbertresults/\n",
    "\n",
    "!aws s3 cp s3://{BUCKET}/{S3_OUTPUT_PATH}/intfloat/e5-large-v2/STSBenchmark.json E5largeV2results.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb3f2eb-81e6-4042-b1b5-3705af42b52e",
   "metadata": {},
   "source": [
    "Now it's time to see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64e2104-b1ec-479f-8ba3-080331229f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pygmentize sbertresults/all-mpnet-base-v2/STSBenchmark.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec1eb96-6264-470c-8411-9dd51a5e5ec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pygmentize sbertresults/all-MiniLM-L6-v2/STSBenchmark.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a9c9f3-76fc-4f26-bdd9-27d7abe3dd3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pygmentize E5largeV2results.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfede560-460a-4494-b1a3-060ff788a4eb",
   "metadata": {},
   "source": [
    "Both MPNET and miniLM highlight excellent results with regard to STS B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6648bb-bdb8-4573-89e9-4ada8cfb12d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Now let's evaluate fastText with SageMaker processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8640c041-396c-4b62-a68a-6256c40ac4e0",
   "metadata": {},
   "source": [
    "Let's evaluate FastText with regard to MTEB, thanks to SageMaker processing. [FastText](https://fasttext.cc/) is a static pre-trained embedding containing support for 157 languages, as long as a tokenization that is enabled on subword level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cbf4d7-a5b8-44b9-af1a-3f9ee587c8b3",
   "metadata": {},
   "source": [
    "What's great with MTEB is that we can create custom model evaluation classes. The only requirement for these classes is to possess an `encode` method whose inputs are list of sentences and outputs are list of vectors. You can do whatever you want inside that class, even by calling external APIS !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd8f93f-7159-47b7-beaa-e6eee3488f8a",
   "metadata": {},
   "source": [
    "### Creating an evaluation script and requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899281fd-08d3-4b46-9fba-592d35efa692",
   "metadata": {},
   "source": [
    "As usual, let's keep our work tidy, create a dedicated folder, put our evaluation script as well as requirements, and run the processing job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8234bd25-e4a7-492a-a42d-b1a46c13d8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p fasttextscripts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d85b48-fcf5-4ea6-9efb-fde32ec8ba57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile fasttextscripts/embeval.py\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "import fasttext\n",
    "from mteb import MTEB\n",
    "import string\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NaiveAvgFastTextModel():\n",
    "    def encode(self, sentences, batch_size=32, **kwargs):\n",
    "        \"\"\" Returns a list of embeddings for the given sentences.\n",
    "        Args:\n",
    "            sentences (`List[str]`): List of sentences to encode\n",
    "            batch_size (`int`): Batch size for the encoding\n",
    "\n",
    "        Returns:\n",
    "            `List[np.ndarray]` or `List[tensor]`: List of embeddings for the given sentences\n",
    "        \"\"\"\n",
    "        model_path = hf_hub_download(repo_id=\"facebook/fasttext-en-vectors\", filename=\"model.bin\")\n",
    "        self.ftmodel = fasttext.load_model(model_path)\n",
    "        res= []\n",
    "        for sentence in sentences:\n",
    "            unpunkt_sentence = sentence.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "            res.append(self.ftmodel.get_sentence_vector(unpunkt_sentence))\n",
    "        return res     \n",
    "\n",
    "if __name__=='__main__':\n",
    "    output_path_folder = \"/opt/ml/processing/eval/\"\n",
    "    model = NaiveAvgFastTextModel()\n",
    "    evaluation = MTEB(tasks=[\"STSBenchmark\"])\n",
    "    evaluation.run(model, eval_splits=[\"test\"], output_folder=output_path_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8cfec2-b95c-465f-ad7b-660ccbc895f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile fasttextscripts/requirements.txt\n",
    "transformers\n",
    "mteb\n",
    "datasets\n",
    "accelerate==0.20.3\n",
    "huggingface\n",
    "fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d67f51-6d08-4660-b498-4edccc023f74",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Launching SageMaker processing job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18318de8-4595-4c1d-91e8-fb00f56fae45",
   "metadata": {},
   "source": [
    "Apart from directory, SageMaker processing job is not different from above function. Let's reuse the utility above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b36dd4-35eb-46fd-b484-765ccdcd6273",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ftres=run_sm_processing_job(\"fasttext\", script_dir = \"fasttextscripts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72392a6a-f08e-4163-8e35-dc53561aa453",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ftres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b887e15-4155-458a-97d5-721e35c9a7a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws s3 cp s3://sagemaker-eu-west-2-175256325518/mteb/eval/fasttext/STSBenchmark.json ftbench.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1973fa4-16b8-4a44-9ba5-73050e3698bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pygmentize ftbench.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5785b78a-3eef-4524-9e9f-f3ba60452b41",
   "metadata": {},
   "source": [
    "We notice that although lower than transformer based embeddings, FastText scores are honorable when handling a similarity task. Old but gold!"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 2.0.0 Python 3.10 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-2:712779665605:image/pytorch-2.0.0-cpu-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
